{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9dda65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    # Read 16-bit TIFF\n",
    "    img_16 = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n",
    "    \n",
    "    # Normalization\n",
    "    img_norm = cv2.normalize(img_16, None, 0, 65535, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Convert to 8-bit preserving dynamic range\n",
    "    img_8bit = np.uint8(img_norm/256)\n",
    "    \n",
    "    # Advanced noise reduction\n",
    "    bilateral_filtered = cv2.bilateralFilter(img_8bit, 9, 75, 75)\n",
    "    \n",
    "    # Adaptive contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    clahe_img = clahe.apply(bilateral_filtered)\n",
    "    \n",
    "    # Background estimation and subtraction\n",
    "    background = cv2.GaussianBlur(clahe_img, (101,101), 0)\n",
    "    subtracted = cv2.subtract(clahe_img, background)\n",
    "    \n",
    "    # Dynamic thresholding\n",
    "    hist = cv2.calcHist([subtracted], [0], None, [256], [0, 256])\n",
    "    hist = hist / hist.sum()\n",
    "    cumulative_hist = np.cumsum(hist)\n",
    "    median_bin = np.searchsorted(cumulative_hist, 0.5)\n",
    "    _, binary = cv2.threshold(subtracted, median_bin*1.5, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    return binary, subtracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d0a5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import shutil\n",
    "import yaml\n",
    "\n",
    "def prepare_yolo_dataset(csv_path, image_dir, output_dir='yolo_dataset'):\n",
    "    # Read annotations\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Create YOLO directory structure\n",
    "    (Path(output_dir)/'images/train').mkdir(parents=True, exist_ok=True)\n",
    "    (Path(output_dir)/'labels/train').mkdir(parents=True, exist_ok=True)\n",
    "    (Path(output_dir)/'images/val').mkdir(parents=True, exist_ok=True)\n",
    "    (Path(output_dir)/'labels/val').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Class mapping\n",
    "    class_map = {'star': 0, 'streak': 1}  # Adjust based on your CSV\n",
    "    \n",
    "    # Process each image\n",
    "    for img_name, group in df.groupby('image'):\n",
    "        img_path = Path(image_dir)/img_name\n",
    "        if not img_path.exists():\n",
    "            continue\n",
    "            \n",
    "        # Split into train/val (80/20)\n",
    "        split = 'train' if hash(img_name) % 5 != 0 else 'val'\n",
    "        \n",
    "        # Copy image (consider converting TIFF to PNG/JPG)\n",
    "        dest_img = Path(output_dir)/f'images/{split}/{img_path.stem}.jpg'\n",
    "        img = cv2.imread(str(img_path), cv2.IMREAD_ANYDEPTH)\n",
    "        img_8bit = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        cv2.imwrite(str(dest_img), img_8bit)\n",
    "        \n",
    "        # Create YOLO format labels\n",
    "        label_path = Path(output_dir)/f'labels/{split}/{img_path.stem}.txt'\n",
    "        with open(label_path, 'w') as f:\n",
    "            for _, row in group.iterrows():\n",
    "                # Convert bbox to YOLO format (normalized cx,cy,w,h)\n",
    "                x_center = (row['bbox_x'] + row['bbox_width']/2) / 4500\n",
    "                y_center = (row['bbox_y'] + row['bbox_height']/2) / 4500\n",
    "                width = row['bbox_width'] / 4500\n",
    "                height = row['bbox_height'] / 4500\n",
    "                \n",
    "                f.write(f\"{class_map[row['object_type']]} {x_center} {y_center} {width} {height}\\n\")\n",
    "    \n",
    "    # Create dataset.yaml\n",
    "    data = {\n",
    "        'path': str(Path(output_dir).absolute()),\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'names': list(class_map.keys()),\n",
    "        'nc': len(class_map)\n",
    "    }\n",
    "    \n",
    "    with open(Path(output_dir)/'dataset.yaml', 'w') as f:\n",
    "        yaml.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04e47c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class AstroYOLO:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "        \n",
    "    def preprocess_image(self,img_path):\n",
    "        # Read 16-bit TIFF\n",
    "        img_16 = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n",
    "        \n",
    "        # Normalization\n",
    "        img_norm = cv2.normalize(img_16, None, 0, 65535, cv2.NORM_MINMAX)\n",
    "        \n",
    "        # Convert to 8-bit preserving dynamic range\n",
    "        img_8bit = np.uint8(img_norm/256)\n",
    "        \n",
    "        # Advanced noise reduction\n",
    "        bilateral_filtered = cv2.bilateralFilter(img_8bit, 9,50, 50)\n",
    "        \n",
    "        # Adaptive contrast enhancement\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "        clahe_img = clahe.apply(bilateral_filtered)\n",
    "        \n",
    "        \n",
    "        # Dynamic thresholding\n",
    "        hist = cv2.calcHist([clahe_img], [0], None, [256], [0, 256])\n",
    "        hist = hist / hist.sum()\n",
    "        cumulative_hist = np.cumsum(hist)\n",
    "        median_bin = np.searchsorted(cumulative_hist, 0.5)\n",
    "        _, binary = cv2.threshold(clahe_img, median_bin*2, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        return binary\n",
    "    def train(self, data_yaml, epochs=100, imgsz=1024):\n",
    "        \"\"\"Train with custom preprocessing\"\"\"\n",
    "        # Load model\n",
    "        self.model = YOLO('custom_yolov8.yaml')\n",
    "        \n",
    "        # Custom training loop\n",
    "        results = self.model.train(\n",
    "            data=data_yaml,\n",
    "            epochs=epochs,\n",
    "            imgsz=imgsz,\n",
    "            batch=8,\n",
    "            augment=True,\n",
    "            degrees=45,\n",
    "            translate=0.1,\n",
    "            scale=0.5,\n",
    "            mosaic=1.0,\n",
    "            pretrained=True,\n",
    "            optimizer='AdamW',\n",
    "            lr0=0.001,\n",
    "            close_mosaic=10,\n",
    "            overlap_mask=False,\n",
    "            rect=True,\n",
    "            # Custom preprocess callback\n",
    "            preprocess=self.preprocess\n",
    "        )\n",
    "        return results\n",
    "    \n",
    "    def predict_large_image(self, img_path, tile_size=1024, overlap=128):\n",
    "        \"\"\"Predict on large 4500x4500 images using tiling\"\"\"\n",
    "        img = self.preprocess(img_path)\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Split into tiles\n",
    "        tiles = []\n",
    "        for y in range(0, h, tile_size-overlap):\n",
    "            for x in range(0, w, tile_size-overlap):\n",
    "                tile = img[y:y+tile_size, x:x+tile_size]\n",
    "                tiles.append((tile, x, y))\n",
    "        \n",
    "        # Process each tile\n",
    "        results = []\n",
    "        for tile, x_offset, y_offset in tiles:\n",
    "            tile_result = self.model.predict(tile, imgsz=tile_size, conf=0.25)\n",
    "            for box in tile_result[0].boxes:\n",
    "                # Convert tile coordinates to original image coordinates\n",
    "                x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                results.append([\n",
    "                    x1 + x_offset,\n",
    "                    y1 + y_offset,\n",
    "                    x2 + x_offset,\n",
    "                    y2 + y_offset,\n",
    "                    box.conf.item(),\n",
    "                    box.cls.item()\n",
    "                ])\n",
    "        \n",
    "        # Apply NMS across all tiles\n",
    "        return self.non_max_suppression(results)\n",
    "\n",
    "    @staticmethod\n",
    "    def non_max_suppression(boxes, iou_thresh=0.5):\n",
    "        \"\"\"Custom NMS for astronomical objects\"\"\"\n",
    "        if len(boxes) == 0:\n",
    "            return []\n",
    "        \n",
    "        boxes = np.array(boxes)\n",
    "        x1 = boxes[:,0]\n",
    "        y1 = boxes[:,1]\n",
    "        x2 = boxes[:,2]\n",
    "        y2 = boxes[:,3]\n",
    "        scores = boxes[:,4]\n",
    "        \n",
    "        areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        order = scores.argsort()[::-1]\n",
    "        \n",
    "        keep = []\n",
    "        while order.size > 0:\n",
    "            i = order[0]\n",
    "            keep.append(i)\n",
    "            \n",
    "            xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "            yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "            xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "            yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "            \n",
    "            w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "            h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "            inter = w * h\n",
    "            ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "            \n",
    "            \n",
    "            inds = np.where(ovr <= iou_thresh)[0]\n",
    "            order = order[inds + 1]\n",
    "        \n",
    "        return boxes[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a172840f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Detect.__init__() takes from 1 to 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m      5\u001b[39m astro_yolo = AstroYOLO()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m results = \u001b[43mastro_yolo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myolo_dataset/dataset.yaml\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[32m      9\u001b[39m astro_yolo.model.export(\u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[33monnx\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# Optional: export to ONNX\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mAstroYOLO.train\u001b[39m\u001b[34m(self, data_yaml, epochs, imgsz)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Train with custom preprocessing\"\"\"\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcustom_yolov8.yaml\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Custom training loop\u001b[39;00m\n\u001b[32m     42\u001b[39m results = \u001b[38;5;28mself\u001b[39m.model.train(\n\u001b[32m     43\u001b[39m     data=data_yaml,\n\u001b[32m     44\u001b[39m     epochs=epochs,\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     preprocess=\u001b[38;5;28mself\u001b[39m.preprocess\n\u001b[32m     60\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\Streak-and-Stars\\stars\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:53\u001b[39m, in \u001b[36mYOLO.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m = new_instance.\u001b[34m__dict__\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\Streak-and-Stars\\stars\\Lib\\site-packages\\ultralytics\\engine\\model.py:146\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28m__import__\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mos\u001b[39m\u001b[33m\"\u001b[39m).environ[\u001b[33m\"\u001b[39m\u001b[33mCUBLAS_WORKSPACE_CONFIG\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m:4096:8\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# to avoid deterministic warnings\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(model).endswith((\u001b[33m\"\u001b[39m\u001b[33m.yaml\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.yml\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28mself\u001b[39m._load(model, task=task)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\Streak-and-Stars\\stars\\Lib\\site-packages\\ultralytics\\engine\\model.py:258\u001b[39m, in \u001b[36mModel._new\u001b[39m\u001b[34m(self, cfg, task, model, verbose)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m.cfg = cfg\n\u001b[32m    257\u001b[39m \u001b[38;5;28mself\u001b[39m.task = task \u001b[38;5;129;01mor\u001b[39;00m guess_model_task(cfg_dict)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mRANK\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# build model\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;28mself\u001b[39m.overrides[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.cfg\n\u001b[32m    260\u001b[39m \u001b[38;5;28mself\u001b[39m.overrides[\u001b[33m\"\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.task\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\Streak-and-Stars\\stars\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:335\u001b[39m, in \u001b[36mDetectionModel.__init__\u001b[39m\u001b[34m(self, cfg, ch, nc, verbose)\u001b[39m\n\u001b[32m    333\u001b[39m     LOGGER.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOverriding model.yaml nc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.yaml[\u001b[33m'\u001b[39m\u001b[33mnc\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with nc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m     \u001b[38;5;28mself\u001b[39m.yaml[\u001b[33m\"\u001b[39m\u001b[33mnc\u001b[39m\u001b[33m\"\u001b[39m] = nc  \u001b[38;5;66;03m# override YAML value\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.save = \u001b[43mparse_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43myaml\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# model, savelist\u001b[39;00m\n\u001b[32m    336\u001b[39m \u001b[38;5;28mself\u001b[39m.names = {i: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.yaml[\u001b[33m\"\u001b[39m\u001b[33mnc\u001b[39m\u001b[33m\"\u001b[39m])}  \u001b[38;5;66;03m# default names dict\u001b[39;00m\n\u001b[32m    337\u001b[39m \u001b[38;5;28mself\u001b[39m.inplace = \u001b[38;5;28mself\u001b[39m.yaml.get(\u001b[33m\"\u001b[39m\u001b[33minplace\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\Streak-and-Stars\\stars\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1494\u001b[39m, in \u001b[36mparse_model\u001b[39m\u001b[34m(d, ch, verbose)\u001b[39m\n\u001b[32m   1491\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1492\u001b[39m     c2 = ch[f]\n\u001b[32m-> \u001b[39m\u001b[32m1494\u001b[39m m_ = torch.nn.Sequential(*(m(*args) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n))) \u001b[38;5;28;01mif\u001b[39;00m n > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# module\u001b[39;00m\n\u001b[32m   1495\u001b[39m t = \u001b[38;5;28mstr\u001b[39m(m)[\u001b[32m8\u001b[39m:-\u001b[32m2\u001b[39m].replace(\u001b[33m\"\u001b[39m\u001b[33m__main__.\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# module type\u001b[39;00m\n\u001b[32m   1496\u001b[39m m_.np = \u001b[38;5;28msum\u001b[39m(x.numel() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m m_.parameters())  \u001b[38;5;66;03m# number params\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: Detect.__init__() takes from 1 to 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "prepare_yolo_dataset('centroids.csv', r'Datasets\\Padded_Raw', 'yolo_dataset')\n",
    "\n",
    "# Train model\n",
    "astro_yolo = AstroYOLO()\n",
    "results = astro_yolo.train('yolo_dataset/dataset.yaml', epochs=100, imgsz=1024)\n",
    "\n",
    "# Save model\n",
    "astro_yolo.model.export(format='onnx')  # Optional: export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ad6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
